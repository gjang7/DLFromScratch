{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Copyrights\n",
    "1. textbook official repository: https://github.com/WegraLee/deep-learning-from-scratch\n",
    "    * 아래 python code들은 [chapter 3](https://github.com/WegraLee/deep-learning-from-scratch/tree/master/ch03)에서 가져왔습니다.\n",
    "1. fork source: https://github.com/ExcelsiorCJH/DLFromScratch [(chapter3)](https://nbviewer.org/github/ExcelsiorCJH/DLFromScratch/blob/master/Chap03-NeuralNetwork/Chap03-NeuralNetwork.ipynb)\n",
    "1. additional repository: https://github.com/SDRLurker/deep-learning [(3장)](https://nbviewer.org/github/SDRLurker/deep-learning/blob/master/3%EC%9E%A5.ipynb)\n",
    "1. [plot_mnist_filters.ipynb](plot_mnist_filters.ipynb)는 \n",
    "[Scikit-learn MNIST 예제](https://scikit-learn.org/stable/auto_examples/neural_networks/plot_mnist_filters.html)의 \n",
    "내용으로 작성되었습니다.\n",
    "\n",
    "### Customized by Gil-Jin Jang"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 파일 설명\n",
    "\n",
    "| 파일명 | 파일 용도 | 관련 절 | 페이지 |\n",
    "|:--   |:--      |:--    |:--      |\n",
    "| [Chap03-NeuralNetwork.ipynb](Chap03-NeuralNetwork.ipynb) | 내용 + 실행가능 코드 | 3.1-3.7 | \n",
    "| [plot_mnist_filters.ipynb](plot_mnist_filters.ipynb) | MNIST Neural Network 학습 및 필터 시각화 예제 | APPENDIX | \n",
    "| [mnist_show.py](https://github.com/WegraLee/deep-learning-from-scratch/blob/master/ch03/mnist_show.py) | MNIST 데이터셋을 읽어와 훈련 데이터 중 0번째 이미지를 화면에 출력합니다. | 3.6.1 손글씨 데이터셋 | 99 |\n",
    "| [neuralnet_mnist.py](neuralnet_mnist.py) | 신경망으로 손글씨 숫자 그림을 추론합니다. 입력층, 은닉층1, 은닉층2, 출력층의 뉴런 수는 각각 784, 50, 100, 10입니다. | 3.6.2 신경망의 추론 처리 | 100 |\n",
    "| [neuralnet_mnist_batch.py](https://github.com/WegraLee/deep-learning-from-scratch/blob/master/ch03/mnist_show.py) | neuralnet_mnist.py에 배치 처리 기능을 더했습니다. | 3.6.3 배치 처리 | 104 |\n",
    "| [relu.py](https://github.com/WegraLee/deep-learning-from-scratch/blob/master/ch03/relu.py) | ReLU 함수를 구현한 코드입니다. | 3.2.7 ReLU 함수 | 76 |\n",
    "| [sample_weight.pkl](sample_weight.pkl) | 미리 학습해둔 가종치 매개변수의 값들입니다. | 3.6.2 신경망의 추론 처리 | 100 |\n",
    "| [sig_step_compare.py](https://github.com/WegraLee/deep-learning-from-scratch/blob/master/ch03/sig_step_compare.py) | 시그모이드 함수와 계단 함수의 그래프 모양을 비교해봅니다. | 3.2.5 시그모이드 함수와 계단 함수 비교 | 74 |\n",
    "| [sigmoid.py](https://github.com/WegraLee/deep-learning-from-scratch/blob/master/ch03/sigmoid.py) | 시그모이드 함수를 구현한 코드입니다. | 3.2.4 시그모이드 함수 구현하기 | 72 |\n",
    "| [step_function.py](https://github.com/WegraLee/deep-learning-from-scratch/blob/master/ch03/step_function.py) | 계단 함수를 구현한 코드입니다. | 3.2.3 계단 함수의 그래프 | 70 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chap03 - 신경망\n",
    "\n",
    "\n",
    "## 목차\n",
    "```\n",
    "3.1 퍼셉트론에서 신경망으로 \n",
    "__3.1.1 신경망의 예 \n",
    "__3.1.2 퍼셉트론 복습 \n",
    "__3.1.3 활성화 함수의 등장 \n",
    "3.2 활성화 함수 \n",
    "__3.2.1 시그모이드 함수 \n",
    "__3.2.2 계단 함수 구현하기 \n",
    "__3.2.3 계단 함수의 그래프 \n",
    "__3.2.4 시그모이드 함수 구현하기 \n",
    "__3.2.5 시그모이드 함수와 계단 함수 비교 \n",
    "__3.2.6 비선형 함수 \n",
    "__3.2.7 ReLU 함수 \n",
    "3.3 다차원 배열의 계산 \n",
    "__3.3.1 다차원 배열 \n",
    "__3.3.2 행렬의 내적 \n",
    "__3.3.3 신경망의 내적 \n",
    "3.4 3층 신경망 구현하기 \n",
    "__3.4.1 표기법 설명 \n",
    "__3.4.2 각 층의 신호 전달 구현하기 \n",
    "__3.4.3 구현 정리 \n",
    "3.5 출력층 설계하기 \n",
    "__3.5.1 항등 함수와 소프트맥스 함수 구현하기 \n",
    "__3.5.2 소프트맥스 함수 구현 시 주의점 \n",
    "__3.5.3 소프트맥스 함수의 특징 \n",
    "__3.5.4 출력층의 뉴런 수 정하기\n",
    "3.6 손글씨 숫자 인식 \n",
    "__3.6.1 MNIST 데이터셋 \n",
    "__3.6.2 신경망의 추론 처리 \n",
    "__3.6.3 배치 처리 \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 퍼셉트론에서 신경망으로"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.1 신경망의 예\n",
    "\n",
    "신경망을 그림으로 나타내면 아래와 같다. 입력층, 은닉층, 출력층은 차례로 0층, 1층, 2층이라 하고 아래의 그림은 **2층 신경망**이다. 그 이유는 가중치($w$, weight)를 갖는 층은 2개뿐이기 때문이다.\n",
    "\n",
    "<!-- <img src=\"./images/3-01.png\" width=\"50%\" height=\"50%\"/> -->\n",
    "<img src=\"./images/neurons.png\" width=\"80%\" height=\"80%\"/>\n",
    "\n",
    "출처: http://happycontrol.tistory.com/entry/인공신경망1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.2 퍼셉트론 복습\n",
    "\n",
    "신경망의 신호 전달 방법을 알아보기 전에 [2장](https://github.com/ExcelsiorCJH/DLFromScratch/blob/master/Chap02-Perceptron/Chap02-Perceptron.ipynb)에서 배웠던 퍼셉트론을 복습해보자. \n",
    "\n",
    "<img src=\"./images/3-03.png\" width=\"30%\" height=\"30%\"/>\n",
    "\n",
    "$$\n",
    "y=\\begin{cases} 0\\quad (b + w_1x_1 +w_2x_2 \\le 0) \\\\ 1 \\quad (b + w_1x_1 + w_2x_2 > 0) \\end{cases}\n",
    "$$\n",
    "\n",
    "여기서 $b$는 **편향(bias)** 을 나타내는 매개변수로 뉴런이 얼마나 쉽게 활성화되느냐를 제어한다. $w_1$과 $w_2$는 각 신호의 **가중치(weight)** 를 나타내는 매개변수로, 각 신호의 영향력을 제어한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위의 식을 다음과 같이 더 간결한 형태로 나타내보자.\n",
    "\n",
    "$$\n",
    "y = h(b+ w_1 x_1 + w_2 x_2)\n",
    "$$\n",
    "$$\n",
    "y = h(x)=\\begin{cases} 0\\quad (x \\le 0) \\\\ 1 \\quad (x > 0) \\end{cases}\n",
    "$$\n",
    "\n",
    "위의 식에서 입력의 총합($b+ w_1 x_1 + w_2 x_2$)이 $h(x)$라는 함수를 거쳐 변환된 뒤, 그 출력값이 $y$가 된다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.3 활성화 함수의 등장\n",
    "\n",
    "위에서 $h(x)$라는 함수처럼, 입력 신호의 총합을 출력 신호로 변환하는 함수를 **활성화 함수(activation function)** 이라고 한다. 이름에서도 알 수 있듯이 활성화 함수는 입력 신호의 총합이 **활성화를 일으키는지를 정하는 역할**을 한다. 위의 식을 다시 써보고 이를 그림으로 나타내 보자.\n",
    "\n",
    "$$\n",
    "a = b + w_1 x_1 + w_2 x_2\n",
    "$$\n",
    "$$\n",
    "y = h(a)\n",
    "$$\n",
    "\n",
    "<img src=\"./images/3-04.png\" width=\"30%\" height=\"30%\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 활성화 함수\n",
    "\n",
    "활성화 함수는 임계값(0)을 경계로 출력이 변하는데, 이런 함수를 **계단함수(step function)** 라 한다. 따라서, \"퍼셉트론에서는 활성화 함수로 계단 함수를 이용한다\"라고 할 수 있다. \n",
    "\n",
    "<!-- 그렇다면, 계단함수 말고 다른 함수를 사용하면 어떻게 될까? 이것이 바로 신경망으로 나아가는 핵심이 된다. -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.2 계단 함수 구현하기\n",
    "계단 함수: 입력이 0을 넘으면 1을 출력, 그 외에는 0을 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def step_function_scalar(x):\n",
    "    if x > 0: return 1\n",
    "    else: return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위의 `step_functon_scalar()`의 인수 `x`는 하나의 실수만 받아들일 수 없고 \n",
    "리스트/튜플/넘파이 배열 등 sequence 형식은 한번에 처리할 수 없다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 1] <class 'list'>\n",
      "[0 1 1] <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "x = [-1.0, 1.0, 2.0]\n",
    "\n",
    "# y = step_function_scalar(x)\n",
    "# TypeError: '>' not supported between instances of 'list' and 'int'\n",
    "\n",
    "# use list comprehension for sequence types\n",
    "y = [step_function_scalar(a) for a in x]\n",
    "print(y, type(y))\n",
    "\n",
    "# use list comprehension for numpy array\n",
    "# output should be converted to numpy array as well \n",
    "import numpy as np\n",
    "x = np.array([-1.0, 1.0, 2.0])\n",
    "y = np.array([step_function_scalar(a) for a in x])\n",
    "print(y, type(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 넘파이에서 효율적으로 `step_function`을 구현하여 보자.\n",
    "\n",
    "넘파이 배열에 비교문을 적용하면 같은 크기의 `True/False` array 로 원소별 결과를 얻을 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[False  True  True]\n",
      "bool <class 'numpy.ndarray'>\n",
      "[[False  True  True]\n",
      " [False False  True]]\n",
      "bool <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "x = np.array([-1.0, 1.0, 2.0])\n",
    "y = x > 0\n",
    "print(y)\n",
    "print(y.dtype, type(y))\n",
    "\n",
    "# 다차원 배열로 가능하다.\n",
    "x = np.array([[-1.0, 1.0, 2.0], [-0.9, -0.1, 0.3]])\n",
    "y = x > 0\n",
    "print(y)\n",
    "print(y.dtype, type(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `True`는 `1`, `False`는 `0`으로 변환할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 1]\n",
      "[[0 1 1]\n",
      " [0 0 1]]\n"
     ]
    }
   ],
   "source": [
    "x = np.array([-1.0, 1.0, 2.0])\n",
    "print((x>0).astype(int))\n",
    "\n",
    "x = np.array([[-1.0, 1.0, 2.0], [-0.9, -0.1, 0.3]])\n",
    "print((x>0).astype(int))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 최종적으로 다차원 입출력 `step_function`을 다음과 같이 구현할 수 있다\n",
    "\n",
    "넘파이의 트릭을 사용하여 구현. 넘파이 배열도 인수로 넣을 수 있음.\n",
    "\n",
    "> In textbook, type 'np.int' is used, but deprecated. Use plain type 'int' instead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 입력: numpy 배열, 출력: numpy 배열, 0/1 int 형식\n",
    "def step_function_numpy(x): return (x>0).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 1]\n",
      "[[0 1 1]\n",
      " [0 0 1]]\n"
     ]
    }
   ],
   "source": [
    "print(step_function_numpy(np.array([-1.0, 1.0, 2.0])))\n",
    "print(step_function_numpy(np.array([[-1.0, 1.0, 2.0], [-0.9, -0.1, 0.3]])))\n",
    "# print(step_function_numpy([-1.0, 1.0, 2.0]))\n",
    "# TypeError: '>' not supported between instances of 'list' and 'int'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 정리\n",
    "- 넘파이 배열에서 부등호 연산을 수행하면 원소 각각에 부등호 연산을 수행한 `bool` 배열이 생성\n",
    "- 배열 `x`의 원소 각각이 `0`보다 크면 `True`, `0` 이하면 `False`로 변환한 새로운 배열 `y`가 생성\n",
    "- `numpy.astype()` 메서드: 넘파이 배열의 자료형을 변환\n",
    "- 파이썬에서는 `bool`을 `int`로 변환하면 `True`는 `1`로, `False`는 `0`으로 변환"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.3 계단 함수의 그래프\n",
    "계단 함수: 입력이 0을 넘으면 1을 출력, 그 외에는 0을 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pylab as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# alternate implementation of step_function\n",
    "def step_function(x): return np.array(x>0, dtype=np.int)\n",
    "\n",
    "x = np.arange(-5.0, 5.0, 0.1)\n",
    "y = step_function(x)\n",
    "\n",
    "plt.plot(x, y)\n",
    "plt.ylim(-0.1, 1.1)  # y축의 범위 지정\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.1, 3.2.4 시그모이드 함수 구현하기\n",
    "\n",
    "신경망에서는 활성화 함수로 시그모이드 함수를 이용하여 신호를 변환하고, 그 변환된 신호를 다음 뉴런에 전달한다. 2장에서 알아본 퍼셉트론과 신경망과의 주된 차이는 활성화 함수라고 할 수 있다.\n",
    "\n",
    "신경망에서 자주 사용되는 활성화 함수 중 하나는 **시그모이드 함수(sigmoid function)**다. 시그모이드(sigmoid)란 'S자 모양'이라는 뜻으로 그래프의 모양을 따서 지은 것이라 한다.\n",
    "\n",
    "$$ h(x) = \\frac{1}{1 + \\text{exp}(-x)} $$\n",
    "\n",
    "<img src=\"./images/3-07.png\" width=\"50%\" height=\"50%\"/>\n",
    "\n",
    "신경망에서는 활성화 함수로 시그모이드 함수를 이용하여 신호를 변환하고, 그 변환된 신호를 다음 뉴런에 전달한다. 2장에서 알아본 퍼셉트론과 신경망과의 주된 차이는 활성화 함수라고 할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 넘파이에서 효율적으로 `sigmoid_function`을 구현하여 보자.\n",
    "\n",
    "- np.exp(-x)는 수식 $e^{-x}$에 해당. 인수 $x$가 넘파이 배열이어도 올바른 결과가 나옴\n",
    "- __브로드캐스트__: 넘파이 배열과 스칼라 값의 연산을 넘파이 배열의 원소 각각과 스칼라 값의 연산으로 바꿔 수행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2. 3. 4.] float64 (3,)\n",
      "[1.         0.5        0.33333333] float64 (3,)\n",
      "[0.36787944 0.13533528 0.04978707] float64 (3,)\n",
      "[0.73105858 0.88079708 0.95257413] float64 (3,)\n"
     ]
    }
   ],
   "source": [
    "def print_vts(x):   # value, dtype, shape 을 출력\n",
    "    print(x, x.dtype, x.shape) \n",
    "\n",
    "t = np.array([1.0, 2.0, 3.0])\n",
    "\n",
    "# 넘파이 배열에 1을 더하면 각각의 원소에 더해짐\n",
    "print_vts(1.0 + t)\n",
    "\n",
    "# 각각의 원소로 1이 나뉘어짐\n",
    "print_vts(1.0 / t)\n",
    "\n",
    "# np.exp(-t)는 각각의 원소에 e^-x 가 적용되고 numpy 배열이 반환됨\n",
    "print_vts(np.exp(-t))\n",
    "\n",
    "# np.exp(-x)가 넘파이 배열을 반환하기 때문에 1 / 1 + np.exp(-x))도 \n",
    "# 같은 크기의 넘파이 배열\n",
    "print_vts(1/(1+np.exp(-t)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.26894142, 0.73105858, 0.88079708])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 최종 구현된 sigmoid 함수\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "x = np.array([-1., 1., 2.])\n",
    "sigmoid(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Draw sigmoid function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "#x = np.arange(-5.0, 5.0, 0.1)\n",
    "x = np.linspace(-5.0, 5.0, 101)\n",
    "y = sigmoid(x)\n",
    "\n",
    "plt.plot(x, y)\n",
    "plt.ylim(-0.1, 1.1)  # y축의 범위 지정\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.5 시그모이드 함수와 계단 함수 비교\n",
    "\n",
    "계단함수와 시그모이드 함수를 각각 살펴보았다. 이제 두 함수의 차이가 무엇인지 알아보자. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = np.linspace(-5.0, 5.0, 101)\n",
    "y1 = sigmoid(x)\n",
    "y2 = step_function(x)\n",
    "\n",
    "plt.plot(x, y1)\n",
    "plt.plot(x, y2, 'k--')\n",
    "plt.ylim(-0.1, 1.1) # y축 범위 지정\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위의 그래프에서 볼 수 있듯이, 계단함수와 시그모이드 함수의 차이는 **'연속성'** 이다. 시그모이드 함수는 곡선이며 입력에 따라 출력이 연속적으로 변하지만, 계단함수는 0을 기준으로 출력이 불연속적으로 변한다. 이러한 시그모이드 함수의 연속성이 신경망 학습에서 중요한 역할을 하게된다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "그리고 계단함수는 0과 1 중 하나의 값만 반환하는 반면, 시그모이드 함수는 0과 1사이의 실수(0.723..., 0.232... 등)를 반환한다. 즉, 퍼셉트론에서는 뉴런(노드)사이에 0 혹은 1이 흘렀다면 신경망에서는 연속적인 실수가 흐른다. 계단함수와 시그모이드 함수 둘 다 입력이 중요하면 큰 값(1에 가까운)을 출력하고 입력이 중요하지 않으면 작은값(0에 가까운)을 출력하며, 입력이 아무리 크거나 작아도 시그모이드 함수의 출력은 항상 0에서 1사이이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.6 비선형 함수 \n",
    "\n",
    "\n",
    "> **신경망에서는 활성화 함수로 비선형 함수를 사용해야한다.** \n",
    "\n",
    "시그모이드 함수는 **비선형 함수(non-linear function)**이다. \n",
    "\n",
    "> **활성화 함수로 선형함수를 사용하지 않는 이유는?**\n",
    "\n",
    "\n",
    "선형함수를 이용하면 신경망의 층을 깊게 하는 의미가 없기 때문이다. 예를 들어 활성화 함수로 $h(x) = cx$를 사용하여 3층 신경망을 구성한다고 하면 $y(x) = h(h(h(x)))$이 되며 이것은 $y(x) = c \\times c \\times c \\times x = c^3 x$ 같다. 즉, 활성화 함수를 $h(x) = c^3 x$로 한번만 사용하여 나타낼 수 있기 때문에 여러 층으로 구성된 신경망을 하나의 층으로 쉽게 나타낼 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h1(x) =  70\n",
      "h1(h1(h1(x))) =  7000\n",
      "h3(x) =  7000\n",
      "ha(x) =  7000\n"
     ]
    }
   ],
   "source": [
    "def h1(x): return 10*x\n",
    "\n",
    "def h3(x): return h1(h1(h1(x)))\n",
    "\n",
    "def ha(x): return (10**3)*x\n",
    "\n",
    "x = 7\n",
    "print('h1(x) = ', h1(x))\n",
    "print('h1(h1(h1(x))) = ', h1(h1(h1(x))))\n",
    "print('h3(x) = ', h3(x))\n",
    "print('ha(x) = ', ha(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.7 ReLU 함수\n",
    "\n",
    "Step과 sigmoid, 그리고 선형 활성화 함수들은 단점이 있다.\n",
    "\n",
    "1. step function은 불연속 함수이기 때문에 양방향 미분이 존재하지 않는다.\n",
    "2. sigmoid function은 연속함수이지만 gradient vanishing 이 일어나기 쉽다. \n",
    "3. linear function 은 gradient vanishing 이 없지만 층을 여러 개 쌓는 효과가 없다. \n",
    "\n",
    "이 세가지 단점을 해결하기 위하여 다음의 **ReLU (Rectified Linear Unit)** 활성화 함수를 사용한다.\n",
    "\n",
    "ReLU는 입력이 0을 넘으면 입력 그대로 출력하고, 0 이하이면 0을 출력하는 함수이다. \n",
    "\n",
    "$$\n",
    "h(x)=\\begin{cases} x \\quad (x > 0) \\\\ 0 \\quad (x \\le 0) \\end{cases}\n",
    "$$\n",
    "\n",
    "<img src=\"./images/3-09.png\" width=\"50%\" height=\"50%\"/>\n",
    "\n",
    "> **ReLU 의 특징**\n",
    "\n",
    "1. 연속함수이며 미분가능하다. 단, 오른쪽 미분과 왼쪽 미분이 다르다.\n",
    "2. 미분은 step function. 즉, 오류가 있거나 필요할 때는 학습하고, 정답이 맞으면 학습을 하지 않는 것을 가능하게 한다.\n",
    "3. 0보다 큰 출력에 대해서는 gradient vashnishing 이 없다. 따라서 층을 깊게 쌓는 것이 가능하다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu(x):\n",
    "    return np.maximum(0, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# drawing ReLU function\n",
    "x = np.arange(-5.0, 5.0, 0.1)\n",
    "y = relu(x)\n",
    "\n",
    "plt.plot(x, y)\n",
    "plt.ylim(-1.0, 5.5)  # y축의 범위 지정\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 다차원 배열의 계산"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3.1 다차원 배열\n",
    "\n",
    "여기서는`numpy`를 이용한 다차원 배열에 대해 알아보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 3 4]\n",
      "np.ndim(A) : 1\n",
      "A.shape : (4,)\n",
      "A.shape[0] : 4\n"
     ]
    }
   ],
   "source": [
    "# 1차원 배열\n",
    "A = np.array([1, 2, 3, 4])\n",
    "print(A)\n",
    "print('np.ndim(A) :', np.ndim(A))\n",
    "print('A.shape :', A.shape)\n",
    "print('A.shape[0] :', A.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2]\n",
      " [3 4]\n",
      " [5 6]]\n",
      "np.ndim(B) : 2\n",
      "B.shape : (3, 2)\n",
      "B.shape[0] : 3\n"
     ]
    }
   ],
   "source": [
    "# 2차원 배열\n",
    "B = np.array([[1, 2], \n",
    "              [3, 4], \n",
    "              [5, 6]])\n",
    "\n",
    "print(B)\n",
    "print('np.ndim(B) :', np.ndim(B))\n",
    "print('B.shape :', B.shape)\n",
    "print('B.shape[0] :', B.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3.2 행렬의 내적(행렬 곱)\n",
    "\n",
    "<img src=\"./images/3-11.png\" width=\"70%\"/>\n",
    "**그림 3-11** 행렬의 곱 계산 방법\n",
    "\n",
    "<img src=\"./images/3-12.png\" width=\"60%\"/>\n",
    "**그림 3-12** 행렬의 곱에서는 대응하는 차원의 원소 수를 일치시킨다.\n",
    "\n",
    "<img src=\"./images/3-13.png\" width=\"70%\"/>\n",
    "**그림 3-13** $\\mathbf{A}$가 2차원 행렬, $\\mathbf{B}$가 1차원 배열일 때도 대응하는 차원의 원소 수를 일치시킨다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A.shape : (2, 2)\n",
      "B.shape : (2, 2)\n",
      "np.dot(A,B) :\n",
      " [[19 22]\n",
      " [43 50]]\n"
     ]
    }
   ],
   "source": [
    "A = np.array([[1, 2],\n",
    "              [3, 4]])\n",
    "\n",
    "B = np.array([[5, 6],\n",
    "              [7, 8]]) \n",
    "\n",
    "print('A.shape :', A.shape)\n",
    "print('B.shape :', B.shape)\n",
    "print('np.dot(A,B) :\\n', np.dot(A, B))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3.3 신경망의 내적\n",
    "\n",
    "아래의 그림처럼 간단한 신경망 예제를 통해 신경망 내적을 계산 해보자.\n",
    "\n",
    "<img src=\"./images/3-14.png\" width=\"100%\"/>\n",
    "**그림 3-14** 행렬의 곱으로 신경망의 계산을 수행한다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X.shape : (2,)\n",
      "W.shape : (2, 3)\n",
      "Y: [ 5 11 17]\n"
     ]
    }
   ],
   "source": [
    "X = np.array([1, 2])\n",
    "W = np.array([[1, 3, 5], \n",
    "              [2, 4, 6]])\n",
    "\n",
    "Y = np.dot(X, W)\n",
    "\n",
    "print('X.shape :', X.shape)\n",
    "print('W.shape :', W.shape)\n",
    "print('Y:', Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4 3층 신경망 구현하기\n",
    "\n",
    "이번에는 아래 그림 처럼 3층 신경망을 구현해 보도록 하자.\n",
    "\n",
    "<img src=\"./images/3-15.png\" width=\"80%\" height=\"80%\"/>\n",
    "**그림 3-15** 3층 신경망: 입력층(layer 0)은 2개, 첫 번째 은닉층(layer 1)은 3개, 두 번째 은닉층(layer 2)은 2개, 출력층(layer 3)은 2개의 뉴런으로 구성된다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4.1 표기법 설명\n",
    "\n",
    "<img src=\"./images/3-16.png\" width=\"65%\" height=\"65%\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4.2 각 층의 신호 전달 구현하기\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/3-17.png\" width=\"80%\" height=\"80%\"/>\n",
    "**그림 3-17** 입력층에서 1층으로 신호전달\n",
    "\n",
    "\n",
    "\n",
    "위의 그림에서 $a_{1}^{(1)}$에 대해 가중치 및 편향의 합으로 나타내면 다음과 같다. \n",
    "\n",
    "$$\n",
    "a_{1}^{(1)} = w_{11}^{(1)} x_1 + w_{12}^{(1)} x_2 + b_{1}^{(1)}\n",
    "$$\n",
    "\n",
    "마찬가지로 $a_{2}^{(1)}$, $a_{3}^{(1)}$에 대해 이를 행렬의 내적을 이용하여 나타내면 아래와 같이 간소화 할 수 있다.\n",
    "\n",
    "$$\n",
    "\\mathbf{A}^{(1)} = \\mathbf{XW}^{(1)} + \\mathbf{B}^{(1)}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이때 행렬 $\\mathbf{A}^{(1)}$, $\\mathbf{X}$, $\\mathbf{B}^{(1)}$, $\\mathbf{W}^{(1)}$은 다음과 같다.\n",
    "\n",
    "$$\n",
    "\\mathbf{A}^{(1)} = \\begin{bmatrix} { a }_{ 1 }^{ (1) } & { a }_{ 2 }^{ (1) } & { a }_{ 3 }^{ (1) } \\end{bmatrix}, \\quad \\mathbf{X} = \\begin{bmatrix} { x }_{ 1 } & x_{ 2 } \\end{bmatrix}, \\quad \\mathbf{B}^{(1)} = \\begin{bmatrix} { b }_{ 1 }^{ (1) } & { b }_{ 2 }^{ (1) } & { b }_{ 3 }^{ (1) } \\end{bmatrix}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\mathbf{W}^{(1)} = \\begin{bmatrix} { w }_{ 11 }^{ (1) } & { w }_{ 21 }^{ (1) } & { w }_{ 31 }^{ (1) } \\\\ { w }_{ 12 }^{ (1) } & { w }_{ 22 }^{ (1) } & { w }_{ 32 }^{ (1) } \\end{bmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W1.shape : (2, 3)\n",
      "X.shape : (2,)\n",
      "B1.shape : (3,)\n",
      "A1.shape : (3,)\n",
      "A1 : [0.3 0.7 1.1]\n"
     ]
    }
   ],
   "source": [
    "X = np.array([1.0, 0.5])\n",
    "W1 = np.array([[0.1, 0.3, 0.5], \n",
    "               [0.2, 0.4, 0.6]])\n",
    "B1 = np.array([0.1, 0.2, 0.3])\n",
    "\n",
    "print('W1.shape :', W1.shape)\n",
    "print('X.shape :', X.shape)\n",
    "print('B1.shape :', B1.shape)\n",
    "\n",
    "A1 = np.dot(X, W1) + B1\n",
    "print('A1.shape :', A1.shape)\n",
    "print('A1 :', A1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/3-18.png\" width=\"80%\" height=\"80%\"/>\n",
    "**그림 3-18** 입력층에서 1층으로 신호전달 후 활성화 함수 적용\n",
    "\n",
    "> Notation: 일반적으로 입력은 $\\mathbf{x}$, 출력은 $\\mathbf{y}$, 은닉층은 latent variable 에 많이 사용되는 $\\mathbf{z}$를 사용한다. 활성화 함수를 통과하지 전의 출력은 $\\mathbf{a}$, 혹은 $net$ 이 널리 많이 사용한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A1 : [0.3 0.7 1.1]\n",
      "Z1 : [0.57444252 0.66818777 0.75026011]\n"
     ]
    }
   ],
   "source": [
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "Z1 = sigmoid(A1)\n",
    "\n",
    "print('A1 :', A1)\n",
    "print('Z1 :', Z1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/3-19.png\" width=\"80%\" height=\"80%\"/>\n",
    "**그림 3-19** 1층에서 2층으로 신호 전달"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Z1.shape : (3,)\n",
      "W2.shape : (3, 2)\n",
      "B2.shape : (2,)\n",
      "A2 : [0.51615984 1.21402696]\n",
      "Z2 : [0.62624937 0.7710107 ]\n"
     ]
    }
   ],
   "source": [
    "W2 = np.array([[0.1, 0.4], \n",
    "               [0.2, 0.5], \n",
    "               [0.3, 0.6]])\n",
    "B2 = np.array([0.1, 0.2])\n",
    "\n",
    "print('Z1.shape :', Z1.shape)\n",
    "print('W2.shape :', W2.shape)\n",
    "print('B2.shape :', B2.shape)\n",
    "\n",
    "A2 = np.dot(Z1, W2) + B2  # 신호 합\n",
    "Z2 = sigmoid(A2)  # 활성화함수 값\n",
    "\n",
    "print('A2 :', A2)\n",
    "print('Z2 :', Z2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/3-20.png\" width=\"80%\" height=\"80%\"/>\n",
    "**그림 3-20** 2층에서 출력층으로의 신호 전달"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**항등 함수(identity function)**: \n",
    "최종단계는 네트워크의 출력을 _그대로 전달한다_. 따라서, 마지막 활성화 함수 $\\sigma(x) = x$ 인 __항등함수__이다. \n",
    "\n",
    "<img src=\"./images/3-21.png\" width=\"30%\"/>\n",
    "**그림 3-21** 항등 함수 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def identity_function(x): return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Notation: 많은 논문이나 교과서에 $\\sigma$를 sigmoid 함수로 더 많이 쓰인다. \n",
    "위의 그림은 수정을 하기 어렵고, 책도 그렇게 되어 있기 때문에 그냥 두었다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W3.shape : (2, 2)\n",
      "B3.shape : (2,)\n",
      "A3.shape : (2,)\n",
      "Y.shape : (2,)\n",
      "A3 : [0.31682708 0.69627909]\n",
      "Y : [0.31682708 0.69627909]\n"
     ]
    }
   ],
   "source": [
    "W3 = np.array([[0.1, 0.3], [0.2, 0.4]])\n",
    "B3 = np.array([0.1, 0.2])\n",
    "\n",
    "A3 = np.dot(Z2, W3) + B3\n",
    "Y = identity_function(A3)  # Y = A3\n",
    "\n",
    "print('W3.shape :', W3.shape)\n",
    "print('B3.shape :', B3.shape)\n",
    "print('A3.shape :', A3.shape)\n",
    "print('Y.shape :', Y.shape)\n",
    "\n",
    "print('A3 :', A3)\n",
    "print('Y :', Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4.3 구현 정리\n",
    "\n",
    "위에서 구현한 것을 정리해 보도록 하자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.31682708 0.69627909]\n"
     ]
    }
   ],
   "source": [
    "def init_network():\n",
    "    network = {}\n",
    "    network['W1'] = np.array([[0.1, 0.3, 0.5], \n",
    "                              [0.2, 0.4, 0.6]])\n",
    "    network['b1'] = np.array([0.1, 0.2, 0.3])\n",
    "    network['W2'] = np.array([[0.1, 0.4], \n",
    "                              [0.2, 0.5], \n",
    "                              [0.3, 0.6]])\n",
    "    network['b2'] = np.array([0.1, 0.2])\n",
    "    network['W3'] = np.array([[0.1, 0.3], \n",
    "                              [0.2, 0.4]])\n",
    "    network['b3'] = np.array([0.1, 0.2])\n",
    "\n",
    "    return network  # dictionary return\n",
    "\n",
    "\n",
    "def forward(network, x):\n",
    "    W1, W2, W3 = network['W1'], network['W2'], network['W3']\n",
    "    b1, b2, b3 = network['b1'], network['b2'], network['b3']\n",
    "    \n",
    "    a1 = np.dot(x, W1) + b1\n",
    "    z1 = sigmoid(a1)\n",
    "    a2 = np.dot(z1, W2) + b2\n",
    "    z2 = sigmoid(a2)\n",
    "    a3 = np.dot(z2, W3) + b3\n",
    "    y = identity_function(a3)\n",
    "    \n",
    "    return y\n",
    "\n",
    "\n",
    "network = init_network()\n",
    "x = np.array([1.0, 0.5])\n",
    "y = forward(network, x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.5 출력층 설계하기\n",
    "\n",
    "신경망은 분류(classification)와 회귀(regression) 둘 다 사용할 수 있다. 대신, 분류인지 회귀인지에 따라 출력층에서 사용하는 활성화 함수가 달라진다. 일반적으로 회귀에는 **항등 함수**를 사용하며, 분류에는 **소프트맥스 함수**를 사용한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5.1 소프트맥스 함수 구현하기\n",
    "\n",
    "<!-- **항등 함수**(identity function)는 입력을 그대로 출력한다. -->\n",
    "\n",
    "분류에 사용하는 **소프트맥스 함수**(softmax function)의 식은 다음과 같다.\n",
    "\n",
    "$$\n",
    "y_k = \\frac{\\exp(a_k)}{\\sum_{i = 1}^{n}{\\exp(a_i)}}\n",
    "$$\n",
    "$\\exp(x)$는 $e^x$, 지수함수(exponential function)이다. \n",
    "$n$은 출력측의 뉴런 수, $y_k$는 그 중 $k$번째 출력임을 뜻한다. 소프트맥스 함수의 분자는 입력 신호 $a_k$의 지수 함수, 분모는 모든 입력 신호의 지수 함수의 합으로 구성된다. \n",
    "\n",
    "<img src=\"./images/3-22.png\" width=\"30%\"/>\n",
    "**그림 3-22** 소프트맥스 함수 \n",
    "\n",
    "출력층의 각 뉴런이 모든 입력 신호에서 영향을 받기 때문에 소프트맥스 함수는 모든 입력 신호로부터 화살표를 받는다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.34985881 18.17414537 54.59815003]\n",
      "74.1221542101633\n",
      "[0.01821127 0.24519181 0.73659691]\n"
     ]
    }
   ],
   "source": [
    "# softmax function implementation example\n",
    "a = np.array([0.3, 2.9, 4.0])\n",
    "exp_a = np.exp(a)   # e^a_k\n",
    "print(exp_a)\n",
    "# [ 1.34985881 18.17414537 54.59815003]\n",
    "\n",
    "sum_exp_a = np.sum(exp_a)   # sum e^a_k\n",
    "print(sum_exp_a)\n",
    "# 74.1221542101633\n",
    "\n",
    "y = exp_a/sum_exp_a  # softmax output\n",
    "print(y)\n",
    "# [0.01821127 0.24519181 0.73659691]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax_0(a):\n",
    "    exp_a = np.exp(a)   # e^a_k\n",
    "    sum_exp_a = np.sum(exp_a)   # sum e^a_k\n",
    "    y = exp_a/sum_exp_a  # softmax output\n",
    "    return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5.2 소프트맥스 함수 구현 시 주의점\n",
    "\n",
    "softmax 함수는 exp 함수를 사용하기 때문에 구현할 때에는 overflow 를 조심해야 한다. \n",
    "예를 들어 $e^{1000}$은 double type으로는 무한대($\\infty$, inf)가 된다. \n",
    "따라서 이런 큰 값끼리 나눗셈을 하면 수치가 **불안정**해진다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e^10, e^-10 = 2.202647e+04, 4.539993e-05, \n",
      "e^100, e^-100 = 2.688117e+43, 3.720076e-44, \n",
      "e^200, e^-200 = 7.225974e+86, 1.383897e-87, \n",
      "e^400, e^-400 = 5.221470e+173, 1.915170e-174, \n",
      "e^600, e^-600 = 3.773020e+260, 2.650397e-261, \n",
      "e^1000, e^-1000 = inf, 0.000000e+00, \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/ipykernel_launcher.py:2: RuntimeWarning: overflow encountered in exp\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "X = [10, 100, 200, 400, 600,1000]\n",
    "for x in X: print('e^{0:d}, e^-{0:d} = {1:.6e}, {2:.6e}, '.format(x,np.exp(x),np.exp(-x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **overflow, underflow, precision, and range of floating-point numbers**: 컴퓨터는 실수를 4바이트(dtype float) 혹은 8바이트(dtype double)와 같이 크기가 유한한 데이터로 저장한다. 따라서 표현할 수 있는 수의 범위(range)가 한정되어 너무 큰 값은 표현할 수 없다는 문제(overflow)가 발생한다. 또한 표현할 수 있는 가장 작은 값의 크기(precision)보가 작은 값이 주어지면 0이 된다(underflow)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Softmax 함수의 개선\n",
    "    - 분모/분자에 같은 상수를 곱해도 softmax 함수의 값은 같다. \n",
    "\n",
    "$$\n",
    "y_k = \\frac{\\exp(a_k)}{\\sum_{i = 1}^{n}{\\exp(a_i)}} = \\frac{C \\exp(a_k)}{\\sum_{i = 1}^{n}{C \\exp(a_i)}} = \\frac{\\exp(a_k + \\log C)}{\\sum_{i = 1}^{n}{\\exp(a_i + \\log C)}}\n",
    "$$\n",
    "\n",
    "범위를 안정적으로 유지하기 위해서 $\\exp(x)$에서 $x \\leq 0$이 만족시키도록 $\\log C$ 값을 정한다(우리가 관심있는 것은 \"최대값\"인 class label을 찾는 것이므로 underflow는 이 경우 크게 문제되지 않는다). 이를 위하여 예측값 중 최대값을 차감한다. \n",
    "\n",
    "$$\\log C \\Leftarrow -\\max_{j} a_j$$\n",
    "$$\n",
    "y_k = \\frac{\\exp(a_k - \\max_{j} a_j)}{\\sum_{i = 1}^{n}{\\exp(a_i - \\max_{j} a_j)}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nan nan nan]\n",
      "[  0 -10 -20]\n",
      "[9.99954600e-01 4.53978686e-05 2.06106005e-09]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/ipykernel_launcher.py:2: RuntimeWarning: overflow encountered in exp\n",
      "  \n",
      "/usr/lib/python3/dist-packages/ipykernel_launcher.py:2: RuntimeWarning: invalid value encountered in true_divide\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "a = np.array([1010, 1000, 990])\n",
    "print(np.exp(a)/np.sum(np.exp(a)))\n",
    "\n",
    "c = np.max(a)\n",
    "print(a-c)\n",
    "print(np.exp(a-c)/np.sum(np.exp(a-c)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9.99954600e-01 4.53978686e-05 2.06106005e-09]\n"
     ]
    }
   ],
   "source": [
    "def softmax(a):\n",
    "    c = np.max(a)\n",
    "    exp_a = np.exp(a - c)  # 오버플로 대책\n",
    "    return exp_a / sum(exp_a)\n",
    "\n",
    "print(softmax(np.array([1010, 1000, 990])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5.3 소프트맥스 함수의 특징"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y : [0.01821127 0.24519181 0.73659691]\n",
      "np.sum(y) : 1.0\n"
     ]
    }
   ],
   "source": [
    "a = np.array([0.3, 2.9, 4.0])\n",
    "y = softmax(a)\n",
    "\n",
    "print('y :', y)\n",
    "print('np.sum(y) :', np.sum(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위의 출력결과 에서 볼 수 있듯이 소프트맥스 함수 출력의 총합은 1이다. 이러한 성질 덕분에 소프트맥스 함수의 출력을 '확률'로 해석할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.6 손글씨 숫자 인식"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.6.1 MNIST 데이터셋\n",
    "\n",
    " MNIST는 미국 인구조사국의 직원들이 쓴 숫자와 고등학생들이 쓴 숫자로 만든 미국 국립표준기술연구소(NIST)의 데이터베이스를 다시 섞어 만든 필기체 숫자 이미지 데이터베이스이다. \n",
    "\n",
    "MNIST 데이터는 딥러닝 예제에서 빠지지 않고 등장하는 데이터라고 할 수 있다.\n",
    "\n",
    "![](./images/mnist.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MNIST 데이터셋은 0부터 9까지 숫자 이미지로 구성됩니다. 훈련 60,000장(인구 센서스 기입), 시험 10,000장(미국 고등학생)이 주어진다. \n",
    "`dataset/mnist.py` 파일에 정의된 `load_mnist()` 함수를 이용하면 쉽게 가지고 올 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.core.pylabtools import figsize\n",
    "\n",
    "import sys, os\n",
    "sys.path.append(os.pardir)  # 부모 디렉터리의 파일을 가져올 수 있도록 설정\n",
    "from dataset.mnist import load_mnist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**sys.path.append(os.pardir)**\n",
    "\n",
    "> mnist.py 파일은 이 책 예제 소스의 `dataset` 디렉토리에 있고, **`from dataset.mnist`** 가 `load_mnist` 함수를 읽어들이기 위해서는 검색 경로에서 `dataset` 폴더를 찾을 수 있어야 한다. 각 예제는 `ch01, ch02, ..., ch08 (or Chap01-...)` 폴더에서 수행한다고 가정하면 검색 경로가 부모 디렉토리가 포함되어야 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train.shape : (60000, 1, 28, 28)\n",
      "t_train.shape : (60000,)\n",
      "x_test.shape : (10000, 1, 28, 28)\n",
      "t_test.shape : (10000,)\n",
      "t_train[0] = 5\n",
      "[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0  30  94 170 253 253 225 253 195   0   0]\n",
      " [  0   0   0   0 219 253 253 198 247   0   0   0   0   0]\n",
      " [  0   0   0   0   0   1 253   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0 190  70   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0 240 253  25   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0  93 253   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0  46 183 253   2   0   0   0]\n",
      " [  0   0   0   0   0  24 221 253 253  78   0   0   0   0]\n",
      " [  0   0   0  18 219 253 253  80   0   0   0   0   0   0]\n",
      " [  0   0 136 253 212 132   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0]]\n"
     ]
    }
   ],
   "source": [
    "(x_train, t_train), (x_test, t_test) = load_mnist(flatten=False, normalize=False, one_hot_label=False)\n",
    "print('x_train.shape :', x_train.shape)\n",
    "print('t_train.shape :', t_train.shape)\n",
    "print('x_test.shape :', x_test.shape)\n",
    "print('t_test.shape :', t_test.shape)\n",
    "print('t_train[0] =',t_train[0])\n",
    "print(x_train[0][0][::2,::2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train.shape : (60000, 1, 28, 28)\n",
      "t_train.shape : (60000, 10)\n",
      "x_test.shape : (10000, 1, 28, 28)\n",
      "t_test.shape : (10000, 10)\n",
      "t_train[0] = [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "[[0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  ]\n",
      " [0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  ]\n",
      " [0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  ]\n",
      " [0.   0.   0.   0.   0.12 0.37 0.67 0.99 0.99 0.88 0.99 0.76 0.   0.  ]\n",
      " [0.   0.   0.   0.   0.86 0.99 0.99 0.78 0.97 0.   0.   0.   0.   0.  ]\n",
      " [0.   0.   0.   0.   0.   0.   0.99 0.   0.   0.   0.   0.   0.   0.  ]\n",
      " [0.   0.   0.   0.   0.   0.   0.75 0.27 0.   0.   0.   0.   0.   0.  ]\n",
      " [0.   0.   0.   0.   0.   0.   0.   0.94 0.99 0.1  0.   0.   0.   0.  ]\n",
      " [0.   0.   0.   0.   0.   0.   0.   0.   0.36 0.99 0.   0.   0.   0.  ]\n",
      " [0.   0.   0.   0.   0.   0.   0.   0.18 0.72 0.99 0.01 0.   0.   0.  ]\n",
      " [0.   0.   0.   0.   0.   0.09 0.87 0.99 0.99 0.31 0.   0.   0.   0.  ]\n",
      " [0.   0.   0.   0.07 0.86 0.99 0.99 0.31 0.   0.   0.   0.   0.   0.  ]\n",
      " [0.   0.   0.53 0.99 0.83 0.52 0.   0.   0.   0.   0.   0.   0.   0.  ]\n",
      " [0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  ]]\n"
     ]
    }
   ],
   "source": [
    "(x_train, t_train), (x_test, t_test) = load_mnist(flatten=False, normalize=True, one_hot_label=True)\n",
    "# normalize == True: 0..255 -> 0..1\n",
    "# one_hot_label == True: 0 -> [1 0 0 ...], 1 -> [0 1 0 ...], 2 -> [0 0 1 ...]\n",
    "print('x_train.shape :', x_train.shape)\n",
    "print('t_train.shape :', t_train.shape)\n",
    "print('x_test.shape :', x_test.shape)\n",
    "print('t_test.shape :', t_test.shape)\n",
    "print('t_train[0] =',t_train[0])\n",
    "with np.printoptions(precision=2, suppress=True):\n",
    "    print(x_train[0][0][::2,::2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train.shape : (60000, 784)\n",
      "t_train.shape : (60000,)\n",
      "x_test.shape : (10000, 784)\n",
      "t_test.shape : (10000,)\n",
      "t_train[0] = 5\n",
      "[0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      " 0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      " 0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.01 0.49 0.65 0.\n",
      " 0.   0.   0.12 0.67 0.99 0.99 0.   0.   0.   0.93 0.99 0.99 0.32 0.\n",
      " 0.   0.   0.86 0.99 0.97 0.   0.   0.   0.   0.31 0.99 0.17 0.   0.\n",
      " 0.   0.   0.   0.99 0.   0.   0.   0.   0.   0.   0.99 0.   0.   0.\n",
      " 0.   0.   0.   0.75 0.   0.   0.   0.   0.   0.   0.14 0.42 0.   0.\n",
      " 0.   0.   0.   0.   0.99 0.   0.   0.   0.   0.   0.   0.99 0.   0.\n",
      " 0.   0.   0.   0.   0.36 0.   0.   0.   0.   0.   0.   0.   0.25 0.\n",
      " 0.   0.   0.   0.   0.72 0.01 0.   0.   0.   0.   0.15 0.99 0.   0.\n",
      " 0.   0.   0.   0.87 0.99 0.   0.   0.   0.   0.09 0.99 0.32 0.   0.\n",
      " 0.   0.   0.86 0.99 0.   0.   0.   0.   0.22 0.99 0.52 0.   0.   0.\n",
      " 0.   0.53 0.83 0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      " 0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  ]\n"
     ]
    }
   ],
   "source": [
    "# loading options for furthur processing\n",
    "# flatten=True, normalize=False, one_hot_label=False\n",
    "(x_train, t_train), (x_test, t_test) = load_mnist(flatten=True, normalize=True, one_hot_label=False)\n",
    "# flatten = True: 1x28x28 -> 784\n",
    "print('x_train.shape :', x_train.shape)\n",
    "print('t_train.shape :', t_train.shape)\n",
    "print('x_test.shape :', x_test.shape)\n",
    "print('t_test.shape :', t_test.shape)\n",
    "print('t_train[0] =',t_train[0])\n",
    "with np.printoptions(precision=2, suppress=True):\n",
    "    print(x_train[0][::4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "figsize(8,4)\n",
    "img = x_train[0].reshape(28, 28)\n",
    "fig1 = plt.subplot(1,2,1).imshow(img, 'gray')\n",
    "plt.xticks(range(0,28,5)), plt.yticks(range(0,28,5));\n",
    "plt.subplot(1,2,2).imshow(img, 'gray')\n",
    "plt.xticks([]), plt.yticks([]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.6.2 신경망의 추론 처리\n",
    "\n",
    "이 예제에서는 `sample_weight.pkl`에 사전에 '학습된 가중치 매개변수'를 이용해 MNIST 데이터를 분류한다.\n",
    "\n",
    "![](./images/mnist_nn.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "아래 예제코드는 [neuralnet_mnist.py](neuralnet_mnist.py)를 jupyter notebook에 그대로 옮긴 것이다.\n",
    "\n",
    "- Definition of a neural network with 2 hidden layers (3 layers) for MNIST\n",
    "- $784 \\times 50 \\times 100 \\times 10$ nodes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sys, os\n",
    "sys.path.append(os.pardir)  # 부모 디렉터리의 파일을 가져올 수 있도록 설정\n",
    "from dataset.mnist import load_mnist\n",
    "from common.functions import sigmoid, softmax\n",
    "\n",
    "import pickle   # 미리 학습된 모델을 읽어들이기 위해 필요 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`get_data()`에서 MNIST 데이터를 불러올 때 `normalize=True`로 해서 데이터를 불러온다. `normalize`를 `True`로 설정하면 이미지의 pixel 값의 범위인 0~255의 값을 255로 나눠, 0.0 ~ 1.0 범위로 변환 해준다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data():\n",
    "    (x_train, t_train), (x_test, t_test) = \\\n",
    "    load_mnist(normalize=True, flatten=True, one_hot_label=False)\n",
    "    # 학습할 필요가 없으니 test data만 return 한다.\n",
    "    return x_test, t_test\n",
    "\n",
    "def init_network():\n",
    "    # pickle 로 저장된 network 를 불러온다 \n",
    "    with open(\"./sample_weight.pkl\", 'rb') as f: network = pickle.load(f)\n",
    "    return network\n",
    "\n",
    "def predict(network, x):\n",
    "    W1, W2, W3 = network['W1'], network['W2'], network['W3']\n",
    "    b1, b2, b3 = network['b1'], network['b2'], network['b3']\n",
    "    z1 = sigmoid(np.dot(x, W1) + b1)\n",
    "    z2 = sigmoid(np.dot(z1, W2) + b2)\n",
    "    y = softmax(np.dot(z2, W3) + b3)\n",
    "    # single line\n",
    "    # y = softmax(np.dot(sigmoid(np.dot(sigmoid(np.dot(x, W1)+b1),W2)+b2),W3)+b3)\n",
    "    return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "학습된 가중치를 이용하여 **정확도(accuracy)**를 계산한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:0.9352\n"
     ]
    }
   ],
   "source": [
    "x, t = get_data()   # load test data\n",
    "network = init_network()  # load model\n",
    "\n",
    "accuracy_cnt = 0\n",
    "for i in range(len(x)):\n",
    "    y = predict(network, x[i])\n",
    "    p = np.argmax(y)  # 확률이 가장 높은 원소의 인덱스를 얻는다.\n",
    "    if p == t[i]:\n",
    "        accuracy_cnt += 1\n",
    "        \n",
    "print(\"Accuracy:\" + str(float(accuracy_cnt)/len(x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.6.3 배치 처리\n",
    "\n",
    "먼저 위에서 작성한 코드는 `for`문을 돌면서, 숫자 이미지 **1 개**가 입력 되었을 때 분류를 수행하는 코드이다.\n",
    "이를 그림으로 나타내면 아래와 같다.\n",
    "\n",
    "<img src=\"./images/3-26.png\" width=\"70%\" height=\"70%\">\n",
    "<center>**그림 3-26** 신경망 각 층의 배열 형상</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "데이터 및 모델 읽어 들이기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, t = get_data()\n",
    "network = init_network()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "다차원 배열에서 차원의 원소 수 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 784)\n",
      "(784,) (784, 50) (50, 100) (100, 10)\n"
     ]
    }
   ],
   "source": [
    "print(x.shape)\n",
    "W1, W2, W3 = network['W1'], network['W2'], network['W3']\n",
    "\n",
    "# y = x * W1 * W2 * W3  (excluding bias vectors)\n",
    "print(x[0].shape, W1.shape, W2.shape, W3.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Forwarding, softmax, and argmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.524 0.033 0.903 0.943 0.015 0.37  0.    1.    0.109 0.914]\n",
      "[0.096 0.059 0.141 0.146 0.058 0.082 0.057 0.155 0.064 0.142] sum(y)= 0.9999999\n",
      "target = 7  prediction = 7\n"
     ]
    }
   ],
   "source": [
    "W1, W2, W3 = network['W1'], network['W2'], network['W3']\n",
    "b1, b2, b3 = network['b1'], network['b2'], network['b3']\n",
    "\n",
    "# forwarding: prediction\n",
    "a3 = sigmoid(np.dot( sigmoid(np.dot( sigmoid(np.dot(x[0], W1)+b1), W2)+b2), W3)+b3)\n",
    "with np.printoptions(precision=3, suppress=True): print(a3)\n",
    "y = softmax(a3)\n",
    "with np.printoptions(precision=3, suppress=True): print(y, 'sum(y)=', np.sum(y))\n",
    "print('target =', t[0], ' prediction =', np.argmax(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Full batch processing\n",
    "\n",
    "여러개의 샘플을 하나의 입력 단위로 묶은 것을 **배치(batch)** 라고 하며,  \n",
    "전체를 한꺼번에 처리하는 것을 **full batch processing**이라고 한다.\n",
    "\n",
    "이미지를 하나씩 forwarding 하는 것과 전체를 한꺼번에 처리하는 것을 비교하여 보자. \n",
    "`time` package 를 이용하여 소요된 시간을 측정하여 비교한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.103,  elapsed time = 1.7012 seconds\n",
      "Accuracy: 0.935,  elapsed time = 0.0439 seconds\n"
     ]
    }
   ],
   "source": [
    "# Using direct matrix multiplication \n",
    "import time\n",
    "\n",
    "W1, W2, W3 = network['W1'], network['W2'], network['W3']\n",
    "b1, b2, b3 = network['b1'], network['b2'], network['b3']\n",
    "\n",
    "# 10000 x ( (784,) x (784, 50) x (50, 100) x (100, 10))\n",
    "start = time.time()\n",
    "accuracy_cnt = 0\n",
    "for i in range(0, len(x)):\n",
    "    yi = softmax(sigmoid(np.dot( sigmoid(np.dot( sigmoid(np.dot(x[0], W1)+b1), W2)+b2), W3)+b3))\n",
    "    accuracy_cnt += np.sum(np.argmax(yi) == t[i])\n",
    "print('Accuracy: {:.3f},  elapsed time = {:.4f} seconds'.format(accuracy_cnt/len(x), time.time()-start))\n",
    "\n",
    "#  (10000, 784) x (784, 50) x (50, 100) x (100, 10)\n",
    "start = time.time()\n",
    "accuracy_cnt = 0\n",
    "y = softmax(sigmoid(np.dot( sigmoid(np.dot( sigmoid(np.dot(x, W1)+b1), W2)+b2), W3)+b3))\n",
    "p = np.argmax(y, axis=1)\n",
    "accuracy_cnt = np.sum(p == t)    \n",
    "print('Accuracy: {:.3f},  elapsed time = {:.4f} seconds'.format(accuracy_cnt/len(x), time.time()-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.935,  elapsed time = 1.4890 seconds\n",
      "Accuracy: 0.935,  elapsed time = 0.0375 seconds\n"
     ]
    }
   ],
   "source": [
    "# Using the internal predict method\n",
    "import time\n",
    "\n",
    "# 10000 x ( (784,) x (784, 50) x (50, 100) x (100, 10))\n",
    "start = time.time()\n",
    "accuracy_cnt = 0\n",
    "for i in range(0, len(x)):\n",
    "    yi = predict(network, x[i])\n",
    "    accuracy_cnt += np.sum(np.argmax(yi) == t[i])\n",
    "print('Accuracy: {:.3f},  elapsed time = {:.4f} seconds'.format(accuracy_cnt/len(x), time.time()-start))\n",
    "\n",
    "#  (10000, 784) x (784, 50) x (50, 100) x (100, 10)\n",
    "start = time.time()\n",
    "accuracy_cnt = 0\n",
    "y = predict(network, x)\n",
    "p = np.argmax(y, axis=1)\n",
    "accuracy_cnt = np.sum(p == t)    \n",
    "print('Accuracy: {:.3f},  elapsed time = {:.4f} seconds'.format(accuracy_cnt/len(x), time.time()-start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mini-batch processing \n",
    "이번에는 이미지 전체가 아닌 **100개**씩을 입력하여 출력결과 또한 **100개씩** 출력하도록 구성해보자. 아래의 그림은 100개의 이미지를 입력했을 때, 100개의 출력이 나오는 것을 나타낸 것이다. 이렇게 전체가 아닌 일부를 하나의 입력 단위로 묶은 것을 **미니배치(mini-batch)** 라고 한다.\n",
    "\n",
    "<img src=\"./images/3-27.png\" width=\"70%\" height=\"70%\"/>\n",
    "<center>**그림 3-27** 미니 배치 처리를 위한 배열들의 형상</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample-wise, accuracy: 0.935,  elapsed time = 1.7531 seconds\n",
      "Full-batch, accuracy: 0.935,  elapsed time = 0.0379 seconds\n",
      "Mini-batch, accuracy: 0.935,  elapsed time = 0.0636 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "# 10000 x ( (784,) x (784, 50) x (50, 100) x (100, 10))\n",
    "start = time.time()\n",
    "accuracy_cnt = 0\n",
    "for i in range(0, len(x)):\n",
    "    yi = predict(network, x[i])\n",
    "    accuracy_cnt += np.sum(np.argmax(yi) == t[i])\n",
    "print('Sample-wise, accuracy: {:.3f},  elapsed time = {:.4f} seconds'.format(accuracy_cnt/len(x), time.time()-start))\n",
    "\n",
    "#  (10000, 784) x (784, 50) x (50, 100) x (100, 10)\n",
    "start = time.time()\n",
    "accuracy_cnt = 0\n",
    "y = predict(network, x)\n",
    "p = np.argmax(y, axis=1)\n",
    "accuracy_cnt = np.sum(p == t)    \n",
    "print('Full-batch, accuracy: {:.3f},  elapsed time = {:.4f} seconds'.format(accuracy_cnt/len(x), time.time()-start))\n",
    "\n",
    "# 100 x 100 x ( (784,) x (784, 50) x (50, 100) x (100, 10))\n",
    "start = time.time()\n",
    "batch_size = 100  # 배치 크기\n",
    "accuracy_cnt = 0\n",
    "for i in range(0, len(x), batch_size):\n",
    "    x_batch = x[i:i+batch_size]\n",
    "    y_batch = predict(network, x_batch)\n",
    "    p = np.argmax(y_batch, axis=1)\n",
    "    accuracy_cnt += np.sum(p == t[i:i+batch_size])\n",
    "    \n",
    "print('Mini-batch, accuracy: {:.3f},  elapsed time = {:.4f} seconds'.format(accuracy_cnt/len(x), time.time()-start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **NOTE** 수치 계산 라이브러리들은 대부분 큰 배열을 효율적으로 처리할 수 있도록 최적화되어 있다. 그리고 데이터 전송 회수를 줄여 버스의 부하(load)를 줄여 주는 것이 컴퓨터 자원을 효율적으로 사용할 수 있다. 하지만 한번에 처리할 수 있는 메모리의 크기의 제한이 있기 때문에(예. GPU memory size) 너무 배치의 크기가 커지면 오히려 효율이 떨어질 수 있다. \n",
    "\n",
    "> 따라서, 배치 크기를 적절하게 설정하여 주는 것이 중요하다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.7 정리\n",
    "\n",
    "- 신경망에서는 활성화 함수로 시그모이드 함수와 ReLU 함수 같은 매끄럽게 변화하는 함수를 이용한다.\n",
    "- numpy의 다차원 배열을 잘 사용하면 신경망을 효율적으로 구현할 수 있다.\n",
    "- 기계학습 문제는 크게 회귀와 분류로 나눌 수 있다.\n",
    "- 출력층의 활성화 함수로는 회귀에서는 주로 항등 함수를, 분류에서는 주로 소프트맥스 함수를 이용한다.\n",
    "- 분류에서는 출력층의 뉴런 수로 분류하려는 클래스 수와 같게 설정한다.\n",
    "- 입력 데이터를 묶은 것을 배치라 하며, 추론 처리를 이 배치 단위로 진행하면 결과를 훨씬 빠르게 얻을 수 있다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
